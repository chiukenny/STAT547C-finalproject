% !TEX root = ../main.tex

% Background section

\section{Background}

\textit{Probabilistic programming} is a modern programming paradigm in which inference is automatically performed on probabilistic models that are specified by the user. The probabilistic models are often in the form of a generative Bayesian model and can be conveniently expressed by a graphical model \cite{Rainforth:2017}. An important aspect of probabilistic programming is that the choice of inference algorithm used for the given probabilistic model is left up to the underlying inference engine. By abstracting away the inference step, users have the flexibility to work with multiple models without needing to modify their inference procedure between models.

However, existing inference algorithms do not work well in all models with one challenge being the possible existence of \textit{symmetries} in the parameterization of a model \cite{Nishihara:2013}. A symmetry can be informally described as a transformation to the parameters that does not change the overall model. If a symmetry is present in a model, it poses a problem of parameter nonidentifiability where the results of inference may be of poor quality and difficult to interpret. Another consequence of having parameter symmetries is that different samples of the model parameters may be strongly correlated as a result. In particular, this may reduce the performance of sampling-based inference algorithms.

The problems of parameter symmetries provide motivation for \textit{detecting} and \textit{breaking} them in probabilistic programs. Symmetry detection refers to determining if a symmetry exists in the parameterization of a model, and symmetry breaking refers to dealing with symmetries in some way such that the problems they cause are no longer of concern. The paper by Nishihara et al. \cite{Nishihara:2013} introduces algorithms for automatically detecting various types of parameter symmetries in a probabilistic programming context. We directly build on their work by formulating two mathematical perspectives of symmetry detection and breaking that have potential to be automatic. We first provide an overview of the required concepts and notations in the remainder of this section.


\subsection{Definitions and notations}

We borrow the notation used by Nishihara et al. \cite{Nishihara:2013}. We represent probabilistic models using factor graphs $(\theta,F)$ with variables $\theta=(\theta_1,...,\theta_N)$ and factors $F=(F_1,...,F_K)$. Let $\Theta$ denote the space of variable values. $\theta\in\Theta$ contains all parameters, latent variables, and observations (which are fixed). $F$ represents all functions, operations, constraints, priors and likelihoods that the posterior distribution may factorize into. Figure \ref{fig:factorgraph} shows an example factor graph from Nishihara et al. \cite{Nishihara:2013}.

\begin{figure}[h]
\begin{center}
\tikz{
\node[latent, xshift=-1cm] (t1) {$\theta_1$};
\node[latent, xshift=1cm] (t2) {$\theta_2$};
\node[latent, yshift=-2cm] (t3) {$\theta_3$};
\node[latent, xshift=2cm, yshift=-2cm] (t4) {$\theta_4$};
\node[obs, xshift=1cm, yshift=-4cm] (t5) {$\theta_5$};
\factor[above=of t1] {f1} {above:Gaussian} {} {t1};
\factor[above=of t2] {f2} {above:Gaussian} {} {t2};
\factor[below=of t1, xshift=1cm] {fplus} {left:sum} {t1,t2} {t3};
\factor[above=of t4] {f4} {above:Gaussian} {} {t4};
\factor[below=of t3, xshift=1cm] {fprod} {left:product} {t3,t4} {t5}
}
\end{center}
\caption{An example factor graph. A variable is represented by a circle and a factor is represented by a square. The shaded circle represents an observed variable.}
\label{fig:factorgraph}
\end{figure}

Given data, the unnormalized posterior distribution can then be expressed as
\[
\prod_kF_k(\theta)
\]
where factor $F_k$ may not necessarily depend on all of $\theta$. In the context of symmetries, priors are not of interest as it is assumed that the parameters of the prior are chosen by the user. The remainder of this report will refer to non-prior factors when considering $F_k$. We now formally introduce symmetries as defined in Nishihara et al. \cite{Nishihara:2013}.
\begin{defn}
A symmetry $\sigma:\Theta\rightarrow\Theta$ is a measurable function with a measurable inverse that satisfies
\[
\prod_kF_k(\theta) \propto \prod_kF_k(\sigma(\theta))
\]
and where if $\theta_n$ is some observed variable, then the symmetry keeps $\theta_n$ fixed. In other words, a symmetry is a transformation on the variables that preserves the overall likelihood up to a scaling constant. One may also consider a specific subset of symmetries, referred to as \textit{local symmetries}.
\end{defn}

\begin{defn}
A local symmetry is a symmetry $\sigma$ that satisfies
\[
F_k(\theta) \propto F_k\left(\sigma(\theta)\right)
\]
for all non-prior factors $F_k$. In contrast to a symmetry, a local symmetry is a transformation on the variables that preserves the likelihood at each factor up to a scaling constant. Nishihara et al. \cite{Nishihara:2013} mainly focuses on detecting local symmetries as they tend to be easier to identify than non-local symmetries.
\end{defn}

The symmetry detection approaches proposed by Nishihara et al. is presented in the context of a probabilistic programming language where it is assumed that all built-in factors have been annotated with constraints or labels that correspond to specific types of symmetries. In this report, we will assume that these annotations are intrinsic properties of the factors $F_k$ and hence are known for a given $(\theta,F)$. The next two subsections provide an overview of two types of symmetries and the approaches for detecting them.


\subsection{Scaling symmetries} \label{sec:scaling}

A local symmetry that scales each variable by some constant without affecting the model is known as a \textit{scaling symmetry}.

\begin{defn}
A scaling symmetry is a local symmetry $\sigma$ such that
\[
\sigma: (\theta_1,...,\theta_N) \longmapsto (r_1\theta_1,...,r_N\theta_N) = (e^{d_1}\theta_1,...,e^{d_N}\theta_N)
\]
where $r_n\in\mathbb{R}_+$ and $d_n=\log r_n$. The scaling symmetry only considers positive scaling by definition. A symmetry that flips the signs of variables is a \textit{sign-flip symmetry} which we only briefly allude to in this report.
\end{defn}

Scaling symmetries are detected by solving for the set of constants that the variables can scale by based on the aggregated factor constraints. Examples of factors and the constraints that they impose on scaling are provided in Table \ref{tab:scaling}. For instance, a \textit{sum factor} that sums inputs $a+b=c$ preserves its integrity under scaling only if both $a$, $b$, and $c$ are scaled by the same amount. This is enforced by the constraint $d_a=d_b=d_c$ that it imposes.

\begin{table}[b]
\centering
\begin{tabular}{|c|c|}
\hline
factor & constraints \\
\hline
$c=a+b$ & $d_a = d_b = d_c$ \\
$c = a\times b$ & $d_c= d_a + d_b$ \\
$x\geq0$ & none \\
\hline
\end{tabular}
\caption{Example factors and the constraints they impose on potential scaling symmetries.}
\label{tab:scaling}
\end{table}

Let $d=(d_1,...,d_N)$ be the vector of scaling exponents. Consider the \textit{constraint matrix} $\mathcal{C}$ constructed by stacking all the constraints in a given factor graph. For example, the mentioned sum factor adds the rows $d_a-d_c=0$ and $d_b-d_c=0$ to $\mathcal{C}$. The null space $\mathcal{N}(\mathcal{C})$ of the constraint matrix then describes the space of scaling exponents that satisfy all the constraints. The scaling symmetries in the factor graph can then be expressed as the set $\{\sigma_d:d\in\mathcal{N}(\mathcal{C})\}$.


\subsection{Permutation symmetries} \label{sec:permutation}

A \textit{permutation symmetry} permutes the variables without changing the overall likelihood. Permutation symmetries are often present in models that have mixture components or latent features and are commonly characterized by the label-switching problem.

\begin{defn}
A permutation symmetry is a non-local symmetry $\sigma$ that permutes the components of $\theta$ while satisfying
\[
\prod_{\text{label}(k)=c}F_k(\sigma(\theta)) = \prod_{\text{label}(k)=c}F_k(\theta)
\]
for all \textit{factor labels} $c$. A factor label is an identifier of a factor that is shared only between factors of the same type. For example, all binary sum factors have the same label but a binary sum factor and a ternary sum factor do not.
\end{defn}

To detect permutation symmetries, all factors must have factor labels. Their arguments (incoming edges of the factor) must also be labeled such that two arguments share the same label if and only if the factor is symmetric with respect to those two. For example, the arguments $a$ and $b$ in the sum factor $c=a+b$ would have the same label if the input variables to $a$ and $b$ are symmetric. Given the labels, the detection problem can then be reduced to a graph \textit{automorphism} problem where the permutation symmetries of the factor graph are the automorphisms that preserve the factor and argument labels. In the context of graphs, an automorphism is a mapping of a graph onto itself that retains how the vertices and edges are connected. Detection of graph automorphisms can be done in quasipolynomial time \cite{Babai:2016} though in practice most graphs can be tested in linear time \cite{Babai:1980}.

Note that the permutation symmetries found through this approach is dependent on the structure of the factor graph. For example, the approach will identify the symmetry across arguments $a$, $b$ and $c$ in the ternary sum factor $a+b+c$ but will only identify the symmetry for $a$, $b$ and for $a+b$, $c$ in the layered binary sum factors $(a+b)+c$.


\subsection{Other symmetries}

We briefly describe two other (local) symmetries without giving formal definitions. As mentioned previously, a sign-flip symmetry flips the signs of variables. The symmetry is similar to the scaling symmetry in that each variable is multiplied by some $r_n$ but with the restriction that $r_n=(-1)^{s_n}$ where $s_n\in\{0,1\}$.


A \textit{translation symmetry} shifts the variables by some amount. The translation symmetry is different from the scaling and sign-flip symmetries in that the translation can depend on other variables, i.e.,
\[
\sigma(\theta)=\theta+t(\theta)
\]
where $t(\theta)$ can depend on the variables not being translated. Detection of translation symmetries still involves aggregating factor constraints but with the difference that the system of equations is now nonlinear.


\subsection{Symmetry breaking}

We reference two examples in the literature where parameter symmetries were explicitly dealt with. Most mentions of symmetry breaking are in the context of specific models that have known symmetries. For example, the Rasch model used in political science and given by
\[
\mathbb{P}(y_i=1) = \text{logit}^{-1}\left(\gamma_{k,i}(\alpha_{j,i}-\beta_{k,i})\right)
\]
has a scaling symmetry where parameter $\gamma_k$ can be scaled by a constant and parameters $\alpha_j$, $\beta_k$ divided by the same constant. Bafumi et al. \cite{Bafumi:2005} proposed two solutions to resolve this aliasing: constrain $\alpha_j$ to have a fixed distribution (e.g. standard normal) or introduce hyperpriors for the parameters and recover the original parameters after inference through normalization. Stephens et al. \cite{Stephens:2000} looked at permutation symmetries in a mixture model. They proposed a relabelling algorithm based on loss functions as an alternative to imposing ordering constraints on the parameters.

These solutions, along with others in the literature, tend to be specific to the model and context. We note the techniques used in these solutions and consider ways to incorporate them in our formulations under a general model context.


\subsection{Equivalence class}

One formulation of symmetry detection and breaking that we will present in this report is based on the idea of \textit{equivalence classes}. We provide a brief review of the definitions and properties of equivalence classes that will be relevant for our formulation.

\begin{defn}
Let $S$ be a set. For all $a,b,c\in S$, an \textit{equivalence relation} $\Xi$ on $S$ is a binary relation that satisfies the following three properties:
\begin{enumerate}

\item
\textbf{reflexivity}: $a\Xequiv a$.

\item
\textbf{symmetry}: if $a\Xequiv b$ then $b\Xequiv a$.

\item
\textbf{transitivity}: if $a\Xequiv b$ and $b\Xequiv c$ then $a\Xequiv c$.

\end{enumerate}
An equivalence relation $\Xi$ partitions $S$ into subsets called equivalence classes. If $a\Xequiv b$ then $a$ and $b$ belong to the same equivalence class. We denote the equivalence class of $a$ as $[a]$. The set of all equivalence classes in $S$ with respect to $\Xi$ is called the \textit{quotient set} of $S$ by $\Xi$, denoted $S/\Xi$.
\end{defn}

\begin{defn}
A \textit{section} is a function $f:S/\Xi\rightarrow S$ that maps an equivalence class to one of its members. The member $f([a])$ is called the \textit{representative} of $[a]$ with respect to $f$.
\end{defn}

% ...